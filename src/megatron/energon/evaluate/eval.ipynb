{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import webdataset as wds\n",
    "import time\n",
    "\n",
    "from megatron.energon import get_savable_loader, get_train_dataset, WorkerConfig\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/lvoegtle/src/megatron-lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp_ds1_prepacked():\n",
    "    worker_config = WorkerConfig(\n",
    "        rank=0,\n",
    "        world_size=1,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return get_savable_loader(\n",
    "        get_train_dataset(\n",
    "            Path(\"/lustre/fsw/portfolios/llmservice/projects/llmservice_nlp_fm/eagle-data-for-energon/eagle_pt_v12_packing.yaml\"),\n",
    "            worker_config=worker_config,\n",
    "            batch_size=1,\n",
    "            shuffle_buffer_size=100,\n",
    "            max_samples_per_sequence=100,\n",
    "        ),\n",
    "        gc_collect_every_n_steps=1000000,\n",
    "    )\n",
    "\n",
    "def cmp_ds2_prepacked_extimg():\n",
    "    worker_config = WorkerConfig(\n",
    "        rank=0,\n",
    "        world_size=1,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return get_savable_loader(\n",
    "        get_train_dataset(\n",
    "            Path(\"/lustre/fsw/portfolios/llmservice/projects/llmservice_nlp_fm/datasets/eagle-next/stage1.5_packed\"),\n",
    "            worker_config=worker_config,\n",
    "            batch_size=1,\n",
    "            shuffle_buffer_size=100,\n",
    "            max_samples_per_sequence=100,\n",
    "        ),\n",
    "        gc_collect_every_n_steps=1000000,\n",
    "    )\n",
    "\n",
    "def cmp_ds3_wds():\n",
    "    torch.data.DataLoader(\n",
    "        \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank=0, worker=0: sample_range=[0, 673035] in 6730 slices, sum(count)=673035: indexes=[0, 100, 200 ...<6725> 672834, 672934, 673035] slices=[shard-000000.tar[0(start), 100], shard-000000.tar[100, 200], shard-000000.tar[200, 300] ...<6725> shard-000013.tar[22734, 22834], shard-000013.tar[22834, 22934], shard-000013.tar[22934, 23035(end)]]\n",
      "rank=0, worker=0: sample_range=[0, 672516] in 6725 slices, sum(count)=672516: indexes=[0, 100, 200 ...<6720> 672315, 672415, 672516] slices=[shard-000000.tar[0(start), 100], shard-000000.tar[100, 200], shard-000000.tar[200, 300] ...<6720> shard-000013.tar[22215, 22315], shard-000013.tar[22315, 22415], shard-000013.tar[22415, 22516(end)]]\n",
      "rank=0, worker=0: sample_range=[0, 673273] in 6733 slices, sum(count)=673273: indexes=[0, 100, 200 ...<6728> 673073, 673173, 673273] slices=[shard-000000.tar[0(start), 100], shard-000000.tar[100, 200], shard-000000.tar[200, 300] ...<6728> shard-000013.tar[22973, 23073], shard-000013.tar[23073, 23173], shard-000013.tar[23173, 23273(end)]]\n",
      "rank=0, worker=0: sample_range=[0, 673098] in 6731 slices, sum(count)=673098: indexes=[0, 100, 200 ...<6726> 672898, 672998, 673098] slices=[shard-000000.tar[0(start), 100], shard-000000.tar[100, 200], shard-000000.tar[200, 300] ...<6726> shard-000013.tar[22798, 22898], shard-000013.tar[22898, 22998], shard-000013.tar[22998, 23098(end)]]\n",
      "rank=0, worker=0: sample_range=[0, 672860] in 6729 slices, sum(count)=672860: indexes=[0, 100, 200 ...<6724> 672660, 672760, 672860] slices=[shard-000000.tar[0(start), 100], shard-000000.tar[100, 200], shard-000000.tar[200, 300] ...<6724> shard-000013.tar[22560, 22660], shard-000013.tar[22660, 22760], shard-000013.tar[22760, 22860(end)]]\n",
      "rank=0, worker=0: sample_range=[0, 673075] in 6731 slices, sum(count)=673075: indexes=[0, 100, 200 ...<6726> 672875, 672975, 673075] slices=[shard-000000.tar[0(start), 100], shard-000000.tar[100, 200], shard-000000.tar[200, 300] ...<6726> shard-000013.tar[22775, 22875], shard-000013.tar[22875, 22975], shard-000013.tar[22975, 23075(end)]]\n",
      "rank=0, worker=0: sample_range=[0, 673256] in 6733 slices, sum(count)=673256: indexes=[0, 100, 200 ...<6728> 673056, 673156, 673256] slices=[shard-000000.tar[0(start), 100], shard-000000.tar[100, 200], shard-000000.tar[200, 300] ...<6728> shard-000013.tar[22956, 23056], shard-000013.tar[23056, 23156], shard-000013.tar[23156, 23256(end)]]\n",
      "rank=0, worker=0: sample_range=[0, 673255] in 6733 slices, sum(count)=673255: indexes=[0, 100, 200 ...<6728> 673055, 673155, 673255] slices=[shard-000000.tar[0(start), 100], shard-000000.tar[100, 200], shard-000000.tar[200, 300] ...<6728> shard-000013.tar[22955, 23055], shard-000013.tar[23055, 23155], shard-000013.tar[23155, 23255(end)]]\n",
      "cmp_ds1_prepacked init: 0.10s\n",
      "cmp_ds1_prepacked: 3.45s\n",
      "cmp_ds1_prepacked: 2.58s\n",
      "cmp_ds1_prepacked: 6.75s\n",
      "cmp_ds1_prepacked: 7.01s\n",
      "cmp_ds1_prepacked: 11.59s\n",
      "cmp_ds1_prepacked: 10.54s\n",
      "cmp_ds1_prepacked: 9.79s\n",
      "cmp_ds1_prepacked: 8.49s\n",
      "cmp_ds1_prepacked: 7.98s\n",
      "cmp_ds1_prepacked: 66.03s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "ds = cmp_ds1_prepacked()\n",
    "print(f\"cmp_ds1_prepacked init: {time.time() - start:.2f}s\")\n",
    "for i in range(10):\n",
    "    start = time.time()\n",
    "    for idx, sample in enumerate(ds):\n",
    "        if idx > 1000:\n",
    "            break\n",
    "    print(f\"cmp_ds1_prepacked: {time.time() - start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
